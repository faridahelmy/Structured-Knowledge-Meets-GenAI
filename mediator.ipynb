{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ontology Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import owlready2\n",
    "from owlready2 import get_ontology\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the OWL/XML file\n",
    "ontology_path = '/Users/faridahelmy/Downloads/OntologyNew.rdf'\n",
    "\n",
    "# Load the ontology\n",
    "onto = get_ontology(ontology_path).load()\n",
    "print(\"Ontology loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Student', 'Course']\n",
      "Object Properties: ['didNotTakeYet', 'droppedAttendance', 'failed', 'earlier', 'hasCompleted', 'hasNotCompleted', 'hasPrerequisite', 'invalidEnrollment', 'regularFailed', 'satisfiesPrerequisite', 'takes']\n",
      "Data Properties: ['GPA', 'courseCode', 'creditHours', 'evenSemester', 'hasSemester', 'isGraduationCase', 'maxCreditHours', 'oddSemester', 'onProbation', 'semesterOffered']\n"
     ]
    }
   ],
   "source": [
    "# Helper function to get a readable name\n",
    "def get_readable_name(entity):\n",
    "    return entity.label.first() if entity.label else entity.name\n",
    "\n",
    "# List all classes with readable names\n",
    "readable_class_names = [get_readable_name(cls) for cls in onto.classes()]\n",
    "print(\"Classes:\", readable_class_names)\n",
    "\n",
    "# List all object properties with readable names\n",
    "readable_object_property_names = [get_readable_name(prop) for prop in onto.object_properties()]\n",
    "print(\"Object Properties:\", readable_object_property_names)\n",
    "\n",
    "# List all data properties with readable names\n",
    "readable_data_property_names = [get_readable_name(prop) for prop in onto.data_properties()]\n",
    "print(\"Data Properties:\", readable_data_property_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SWRL Rules: 0\n"
     ]
    }
   ],
   "source": [
    "# List all SWRL rules in the ontology\n",
    "swrl_rules = list(onto.rules())\n",
    "print(f\"Total SWRL Rules: {len(swrl_rules)}\")\n",
    "\n",
    "# Display each rule with its body (antecedent) and head (consequent)\n",
    "for rule in swrl_rules:\n",
    "    print(\"\\nRule:\")\n",
    "    print(f\"  Name: {rule.name}\")\n",
    "\n",
    "    # Display the antecedent (body) of the rule\n",
    "    print(\"  Antecedent (body):\")\n",
    "    for atom in rule.body:\n",
    "        print(f\"    {atom}\")\n",
    "\n",
    "    # Display the consequent (head) of the rule\n",
    "    print(\"  Consequent (head):\")\n",
    "    for atom in rule.head:\n",
    "        print(f\"    {atom}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in the ontology:\n",
      "OntologyNew.Student\n",
      "OntologyNew.Course\n"
     ]
    }
   ],
   "source": [
    "# List all classes in the ontology to see their exact names\n",
    "all_classes = list(onto.classes())\n",
    "print(\"Classes in the ontology:\")\n",
    "for cls in all_classes:\n",
    "    print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_classes_by_label(ontology):\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping from class labels to the class objects.\n",
    "    \"\"\"\n",
    "    class_label_mapping = {}\n",
    "    for cls in ontology.classes():\n",
    "        readable_name = get_readable_name(cls)\n",
    "        class_label_mapping[readable_name] = cls\n",
    "    return class_label_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_instances_of_class_by_label(ontology, label_to_search):\n",
    "    \"\"\"\n",
    "    Searches for a class by its label and lists all its instances.\n",
    "    \"\"\"\n",
    "    # Get the mapping of class labels to class objects\n",
    "    class_label_mapping = map_classes_by_label(ontology)\n",
    "\n",
    "    # Find the class using the provided label\n",
    "    class_to_search = class_label_mapping.get(label_to_search)\n",
    "\n",
    "    if class_to_search is None:\n",
    "        print(f\"Class with label '{label_to_search}' not found.\")\n",
    "        return\n",
    "\n",
    "    # List all instances of the found class\n",
    "    instances = list(class_to_search.instances())\n",
    "    if not instances:\n",
    "        print(f\"No instances found for the class with label '{label_to_search}'.\")\n",
    "    else:\n",
    "        print(f\"Instances of the class '{label_to_search}':\")\n",
    "        for instance in instances:\n",
    "            instance_label = get_readable_name(instance)\n",
    "            print(f\"- {instance}, label: {instance_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances of the class 'Course':\n",
      "- OntologyNew.Advanced_Computer_Lab2, label: Advanced Computer Lab2\n",
      "- OntologyNew.Advanced_Computer_Lab3, label: Advanced Computer Lab3\n",
      "- OntologyNew.Theory_of_Computation, label: Theory of Computation\n",
      "- OntologyNew.Introduction_to_Computer_Programming, label: Introduction to Computer Programming\n",
      "- OntologyNew.Artificial_Intelligence, label: Artificial Intelligence\n",
      "- OntologyNew.Data_Structures_and_Algorithms, label: Data Structures and Algorithms\n",
      "- OntologyNew.Introduction_to_Computer_Science, label: Introduction to Computer Science\n",
      "- OntologyNew.Bachelor_Thesis, label: Bachelor Thesis\n",
      "- OntologyNew.Chem, label: Chem\n",
      "- OntologyNew.ChemLab, label: ChemLab\n",
      "- OntologyNew.Compiler, label: Compiler\n",
      "- OntologyNew.Computer_Graphics, label: Computer Graphics\n",
      "- OntologyNew.Computer_Organization_and_System_Programming, label: Computer Organization and System Programming\n",
      "- OntologyNew.Digital_Logic_Design, label: Digital Logic Design\n",
      "- OntologyNew.Computer_System_Architecture, label: Computer System Architecture\n",
      "- OntologyNew.Computer_Vision, label: Computer Vision\n",
      "- OntologyNew.Concepts_of_Programming_Languages, label: Concepts of Programming Languages\n",
      "- OntologyNew.Data_Base_I, label: Data Base I\n",
      "- OntologyNew.Data_Bases_II, label: Data Bases II\n",
      "- OntologyNew.Digital_System_Design, label: Digital System Design\n",
      "- OntologyNew.Electric_Circuits_I, label: Electric Circuits I\n",
      "- OntologyNew.Electric_Circuits_II, label: Electric Circuits II\n",
      "- OntologyNew.Embedded_System_Architecture, label: Embedded System Architecture\n",
      "- OntologyNew.Introduction_to_Communication_Networks, label: Introduction to Communication Networks\n",
      "- OntologyNew.Introduction_to_Management, label: Introduction to Management\n",
      "- OntologyNew.Introduction_to_Media_Engineering, label: Introduction to Media Engineering\n",
      "- OntologyNew.Mathematics_I, label: Mathematics I\n",
      "- OntologyNew.Maths, label: Maths\n",
      "- OntologyNew.Mathematics_III, label: Mathematics III\n",
      "- OntologyNew.Mathematics_IV_Probability_and_Statistics, label: Mathematics IV Probability and Statistics\n",
      "- OntologyNew.Microprocessors, label: Microprocessors\n",
      "- OntologyNew.Network_and_Media_Lab, label: Network and Media Lab\n",
      "- OntologyNew.Operating_Systems, label: Operating Systems\n",
      "- OntologyNew.Physics, label: Physics\n",
      "- OntologyNew.Physics_II, label: Physics II\n",
      "- OntologyNew.Production_Technology, label: Production Technology\n",
      "- OntologyNew.Project_Management, label: Project Management\n",
      "- OntologyNew.Seminar, label: Seminar\n",
      "- OntologyNew.Signal_and_System_Theory, label: Signal and System Theory\n",
      "- OntologyNew.Software_Engineering, label: Software Engineering\n",
      "- OntologyNew.'Advanced_Computer_Lab', label: Advanced Computer Lab\n",
      "- OntologyNew.'Computer_and_Network_Security', label: Computer and Network Security\n",
      "- OntologyNew.Engineering_Drawing_&_Design, label: Engineering Drawing & Design\n",
      "- OntologyNew.Mathematics_V_(Discrete_Math), label: Mathematics V (Discrete Math)\n",
      "- OntologyNew.Physics_III_(p), label: Physics III (p)\n",
      "- OntologyNew.Physics_III_(t), label: Physics III (t)\n"
     ]
    }
   ],
   "source": [
    "# Check instances for the \"Course\" class\n",
    "list_instances_of_class_by_label(onto, \"Course\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total individuals in the ontology: 49\n",
      "OntologyNew.Advanced_Computer_Lab2 [OntologyNew.Course]\n",
      "OntologyNew.Advanced_Computer_Lab3 [OntologyNew.Course]\n",
      "OntologyNew.Theory_of_Computation [OntologyNew.Course]\n",
      "OntologyNew.Introduction_to_Computer_Programming [OntologyNew.Course]\n",
      "OntologyNew.Analysis_and_Design_of_Algorithms [owl.Thing]\n",
      "OntologyNew.Artificial_Intelligence [OntologyNew.Course]\n",
      "OntologyNew.Data_Structures_and_Algorithms [OntologyNew.Course]\n",
      "OntologyNew.Introduction_to_Computer_Science [OntologyNew.Course]\n",
      "OntologyNew.Bachelor_Thesis [OntologyNew.Course]\n",
      "OntologyNew.Chem [OntologyNew.Course]\n",
      "OntologyNew.ChemLab [OntologyNew.Course]\n",
      "OntologyNew.Compiler [OntologyNew.Course]\n",
      "OntologyNew.Computer_Graphics [OntologyNew.Course]\n",
      "OntologyNew.Computer_Organization_and_System_Programming [OntologyNew.Course]\n",
      "OntologyNew.Digital_Logic_Design [OntologyNew.Course]\n",
      "OntologyNew.Computer_Programming_Lab [owl.Thing]\n",
      "OntologyNew.Computer_System_Architecture [OntologyNew.Course]\n",
      "OntologyNew.Computer_Vision [OntologyNew.Course]\n",
      "OntologyNew.Concepts_of_Programming_Languages [OntologyNew.Course]\n",
      "OntologyNew.Data_Base_I [OntologyNew.Course]\n",
      "OntologyNew.Data_Bases_II [OntologyNew.Course]\n",
      "OntologyNew.Digital_System_Design [OntologyNew.Course]\n",
      "OntologyNew.Electric_Circuits_I [OntologyNew.Course]\n",
      "OntologyNew.Electric_Circuits_II [OntologyNew.Course]\n",
      "OntologyNew.Embedded_System_Architecture [OntologyNew.Course]\n",
      "OntologyNew.Introduction_to_Communication_Networks [OntologyNew.Course]\n",
      "OntologyNew.Introduction_to_Management [OntologyNew.Course]\n",
      "OntologyNew.Introduction_to_Media_Engineering [OntologyNew.Course]\n",
      "OntologyNew.Mathematics_I [OntologyNew.Course]\n",
      "OntologyNew.Maths [OntologyNew.Course]\n",
      "OntologyNew.Mathematics_III [OntologyNew.Course]\n",
      "OntologyNew.Mathematics_IV_Probability_and_Statistics [OntologyNew.Course]\n",
      "OntologyNew.Microprocessors [OntologyNew.Course]\n",
      "OntologyNew.Network_and_Media_Lab [OntologyNew.Course]\n",
      "OntologyNew.Operating_Systems [OntologyNew.Course]\n",
      "OntologyNew.Physics [OntologyNew.Course]\n",
      "OntologyNew.Physics_II [OntologyNew.Course]\n",
      "OntologyNew.Production_Technology [OntologyNew.Course]\n",
      "OntologyNew.Project_Management [OntologyNew.Course]\n",
      "OntologyNew.Seminar [OntologyNew.Course]\n",
      "OntologyNew.Signal_and_System_Theory [OntologyNew.Course]\n",
      "OntologyNew.Software_Engineering [OntologyNew.Course]\n",
      "OntologyNew.'Advanced_Computer_Lab' [OntologyNew.Course]\n",
      "OntologyNew.'Computer_and_Network_Security' [OntologyNew.Course]\n",
      "OntologyNew.Engineering_Drawing_&_Design [OntologyNew.Course]\n",
      "OntologyNew.Mathematics_V_(Discrete_Math) [OntologyNew.Course]\n",
      "OntologyNew.Physics_III_(p) [OntologyNew.Course]\n",
      "OntologyNew.Physics_III_(t) [OntologyNew.Course]\n",
      "OntologyNew.Farida_Test [OntologyNew.Student]\n"
     ]
    }
   ],
   "source": [
    "# List all individuals in the ontology to check if any exist\n",
    "all_individuals = list(onto.individuals())\n",
    "print(f\"Total individuals in the ontology: {len(all_individuals)}\")\n",
    "for individual in all_individuals:\n",
    "    print(individual, individual.is_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes and their IRIs in the ontology:\n",
      "Class: OntologyNew.Student, IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Student\n",
      "Class: OntologyNew.Course, IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Course\n"
     ]
    }
   ],
   "source": [
    "# List all classes in the ontology with their IRIs\n",
    "print(\"Classes and their IRIs in the ontology:\")\n",
    "for cls in onto.classes():\n",
    "    print(f\"Class: {cls}, IRI: {cls.iri}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course\n",
      "Student\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://localhost:3030/NewOntologyTrial/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT DISTINCT ?class ?label\n",
    "    WHERE { \n",
    "        ?class a owl:Class .\n",
    "        OPTIONAL { ?class rdfs:label ?label }\n",
    "    }\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    class_uri = result[\"class\"][\"value\"]\n",
    "    label = result.get(\"label\", {}).get(\"value\", class_uri)  # Fallback to URI if label is missing\n",
    "    print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Configure your SPARQL endpoint\n",
    "sparql = SPARQLWrapper(\"http://localhost:3030/NewOntologyTrial/sparql\")\n",
    "\n",
    "def execute_query(query):\n",
    "    \"\"\"\n",
    "    Execute a SPARQL query and return results.\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rule_1():\n",
    "    \"\"\"\n",
    "    Rule 1: Invalid Enrollment due to unmet prerequisites.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "   PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "   PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "   PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "   PREFIX main: <http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#>\n",
    "    SELECT DISTINCT ?s ?course\n",
    "    WHERE { \n",
    "        ?s a main:Student .\n",
    "        ?s main:takes ?course .\n",
    "        ?course main: hasPrerequisite ?prereq .\n",
    "        FILTER NOT EXISTS {\n",
    "            ?s main:hasCompleted ?prereq .\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    return execute_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX main: <http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#>\n",
    "    SELECT ?course\n",
    "WHERE {\n",
    "  ?course a main:Course ;\n",
    "          main:evenSemester true .\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule Checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m    Extract SWRL rules from the ontology.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(ontology\u001b[39m.\u001b[39mswrl_rules)\n\u001b[0;32m----> 8\u001b[0m extract_rules(onto)\n",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m, in \u001b[0;36mextract_rules\u001b[0;34m(ontology)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_rules\u001b[39m(ontology):\n\u001b[1;32m      4\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m    Extract SWRL rules from the ontology.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(ontology\u001b[39m.\u001b[39;49mswrl_rules)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "import rdflib\n",
    "def extract_rules(ontology):\n",
    "    \"\"\"\n",
    "    Extract SWRL rules from the ontology.\n",
    "    \"\"\"\n",
    "    return list(ontology.swrl_rules)\n",
    "extract_rules(onto)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Input parsing and Student instance creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentInfoProcessor:\n",
    "    def __init__(self, ontology):\n",
    "        self.ontology = ontology\n",
    "\n",
    "    def find_class_by_label(self, class_label):\n",
    "        \"\"\"\n",
    "        Finds a class in the ontology based on its label.\n",
    "        \"\"\"\n",
    "        for cls in self.ontology.classes():\n",
    "            if cls.label and class_label in cls.label:\n",
    "                return cls\n",
    "        print(f\"Class with label '{class_label}' not found.\")\n",
    "        return None\n",
    "\n",
    "    def find_instance_by_label(self, instance_label):\n",
    "        \"\"\"\n",
    "        Finds an instance in the ontology based on its label.\n",
    "        \"\"\"\n",
    "        for instance in self.ontology.individuals():\n",
    "            if instance.label and instance_label in instance.label:\n",
    "                return instance\n",
    "        print(f\"Instance with label '{instance_label}' not found.\")\n",
    "        return None\n",
    "\n",
    "    def parse_student_info(self, prompt):\n",
    "        \"\"\"\n",
    "        Parses the natural language input prompt to extract student information.\n",
    "        \"\"\"\n",
    "        # Extract GPA\n",
    "        gpa_match = re.search(r\"GPA\\s*[:=]\\s*(\\d+\\.\\d+)\", prompt, re.IGNORECASE)\n",
    "        gpa = float(gpa_match.group(1)) if gpa_match else 0.0\n",
    "\n",
    "        # Extract failed courses\n",
    "        failed_courses_match = re.search(r\"Failed Courses\\s*[:=]\\s*(.+)\", prompt, re.IGNORECASE)\n",
    "        failed_courses = (\n",
    "            [course.strip() for course in failed_courses_match.group(1).split(\",\")]\n",
    "            if failed_courses_match\n",
    "            else []\n",
    "        )\n",
    "\n",
    "        # Extract unattended courses\n",
    "        unattended_courses_match = re.search(r\"Unattended Courses\\s*[:=]\\s*(.+)\", prompt, re.IGNORECASE)\n",
    "        unattended_courses = (\n",
    "            [course.strip() for course in unattended_courses_match.group(1).split(\",\")]\n",
    "            if unattended_courses_match\n",
    "            else []\n",
    "        )\n",
    "\n",
    "        # Extract graduation case status\n",
    "        is_graduation_case_match = re.search(r\"Graduation Case\\s*[:=]\\s*(true|false)\", prompt, re.IGNORECASE)\n",
    "        is_graduation_case = is_graduation_case_match.group(1).lower() == \"true\" if is_graduation_case_match else False\n",
    "\n",
    "        # Extract the student label\n",
    "        student_label_match = re.search(r\"Student Label\\s*[:=]\\s*(.+)\", prompt, re.IGNORECASE)\n",
    "        student_label = student_label_match.group(1).strip() if student_label_match else \"Student_1\"\n",
    "\n",
    "        return {\n",
    "            \"gpa\": gpa,\n",
    "            \"failed_courses\": failed_courses,\n",
    "            \"unattended_courses\": unattended_courses,\n",
    "            \"is_graduation_case\": is_graduation_case,\n",
    "            \"student_label\": student_label,\n",
    "        }\n",
    "\n",
    "    def create_student_instance(self, student_info):\n",
    "      student_class = self.find_class_by_label(\"Student\")\n",
    "      if student_class is None:\n",
    "          raise ValueError(\"The 'Student' class could not be found in the ontology.\")\n",
    "\n",
    "      student = student_class(student_info[\"student_label\"])\n",
    "\n",
    "      # Set GPA and verify\n",
    "      student.GPA = [student_info[\"gpa\"]]\n",
    "      print(f\"Set GPA for {student_info['student_label']}: {student.GPA}\")\n",
    "\n",
    "      # Set graduation case status and verify\n",
    "      student.isGraduationCase = [student_info[\"is_graduation_case\"]]\n",
    "      print(f\"Set isGraduationCase for {student_info['student_label']}: {student.isGraduationCase}\")\n",
    "\n",
    "      # Map failed courses\n",
    "      for course_label in set(student_info[\"failed_courses\"]):\n",
    "          course_instance = self.find_instance_by_label(course_label)\n",
    "          if course_instance:\n",
    "              student.failed.append(course_instance)\n",
    "              print(f\"Mapped failed course {course_label} for {student_info['student_label']}\")\n",
    "\n",
    "      # Map unattended courses\n",
    "      for course_label in set(student_info[\"unattended_courses\"]):\n",
    "          course_instance = self.find_instance_by_label(course_label)\n",
    "          if course_instance:\n",
    "              student.didNotTakeYet.append(course_instance)\n",
    "              print(f\"Mapped unattended course {course_label} for {student_info['student_label']}\")\n",
    "\n",
    "      # Infer and map completed courses\n",
    "      all_courses = [ind for ind in self.ontology.individuals() if self.find_class_by_label(\"Course\") in ind.is_a]\n",
    "      for course in all_courses:\n",
    "          course_label = course.label.first() if course.label else None\n",
    "          if course_label and course_label not in student_info[\"failed_courses\"] and course_label not in student_info[\"unattended_courses\"]:\n",
    "              student.hasCompleted.append(course)\n",
    "              print(f\"Inferred completed course {course_label} for {student_info['student_label']}\")\n",
    "\n",
    "      print(f\"Student '{student_info['student_label']}' instance created successfully.\")\n",
    "      return student\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "   PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "   PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "   PREFIX main: <http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#>\n",
    "    SELECT ?course ?prerequisite ?creditHours ?oddSemester\n",
    "WHERE {\n",
    "  ?course a main:Course ;\n",
    "          main:creditHours ?creditHours ;\n",
    "          main:hasPrerequisite ?prerequisite ;\n",
    "          main:oddSemester ?oddSemester .\n",
    "  FILTER (?course IN (main:Computer_Graphics, main:Analysis_and_Design_of_Algorithms, \n",
    "                      main:Computer_Vision, main:Advanced_Computer_Lab3))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set GPA for Farida_Test: [2.78]\n",
      "Set isGraduationCase for Farida_Test: [True]\n",
      "Mapped failed course Analysis and Design of Algorithms for Farida_Test\n",
      "Mapped failed course Computer Graphics for Farida_Test\n",
      "Mapped unattended course Advanced Computer Lab3 for Farida_Test\n",
      "Mapped unattended course Computer Vision for Farida_Test\n",
      "Inferred completed course Advanced Computer Lab2 for Farida_Test\n",
      "Inferred completed course Theory of Computation for Farida_Test\n",
      "Inferred completed course Introduction to Computer Programming for Farida_Test\n",
      "Inferred completed course Artificial Intelligence for Farida_Test\n",
      "Inferred completed course Data Structures and Algorithms for Farida_Test\n",
      "Inferred completed course Introduction to Computer Science for Farida_Test\n",
      "Inferred completed course Bachelor Thesis for Farida_Test\n",
      "Inferred completed course Chem for Farida_Test\n",
      "Inferred completed course ChemLab for Farida_Test\n",
      "Inferred completed course Compiler for Farida_Test\n",
      "Inferred completed course Computer Organization and System Programming for Farida_Test\n",
      "Inferred completed course Digital Logic Design for Farida_Test\n",
      "Inferred completed course Computer System Architecture for Farida_Test\n",
      "Inferred completed course Concepts of Programming Languages for Farida_Test\n",
      "Inferred completed course Data Base I for Farida_Test\n",
      "Inferred completed course Data Bases II for Farida_Test\n",
      "Inferred completed course Digital System Design for Farida_Test\n",
      "Inferred completed course Electric Circuits I for Farida_Test\n",
      "Inferred completed course Electric Circuits II for Farida_Test\n",
      "Inferred completed course Embedded System Architecture for Farida_Test\n",
      "Inferred completed course Introduction to Communication Networks for Farida_Test\n",
      "Inferred completed course Introduction to Management for Farida_Test\n",
      "Inferred completed course Introduction to Media Engineering for Farida_Test\n",
      "Inferred completed course Mathematics I for Farida_Test\n",
      "Inferred completed course Maths for Farida_Test\n",
      "Inferred completed course Mathematics III for Farida_Test\n",
      "Inferred completed course Mathematics IV Probability and Statistics for Farida_Test\n",
      "Inferred completed course Microprocessors for Farida_Test\n",
      "Inferred completed course Network and Media Lab for Farida_Test\n",
      "Inferred completed course Operating Systems for Farida_Test\n",
      "Inferred completed course Physics for Farida_Test\n",
      "Inferred completed course Physics II for Farida_Test\n",
      "Inferred completed course Production Technology for Farida_Test\n",
      "Inferred completed course Project Management for Farida_Test\n",
      "Inferred completed course Seminar for Farida_Test\n",
      "Inferred completed course Signal and System Theory for Farida_Test\n",
      "Inferred completed course Software Engineering for Farida_Test\n",
      "Inferred completed course Advanced Computer Lab for Farida_Test\n",
      "Inferred completed course Computer and Network Security for Farida_Test\n",
      "Inferred completed course Engineering Drawing & Design for Farida_Test\n",
      "Inferred completed course Mathematics V (Discrete Math) for Farida_Test\n",
      "Inferred completed course Physics III (p) for Farida_Test\n",
      "Inferred completed course Physics III (t) for Farida_Test\n",
      "Student 'Farida_Test' instance created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Example prompt\n",
    "student_prompt = \"\"\"\n",
    "GPA: 2.78\n",
    "Failed Courses: Computer Graphics, Analysis and Design of Algorithms\n",
    "Unattended Courses: Computer Vision, Advanced Computer Lab3\n",
    "Graduation Case: true\n",
    "Student Label: Farida_Test\n",
    "\"\"\"\n",
    "\n",
    "student_processor = StudentInfoProcessor(onto)\n",
    "\n",
    "# Parse the student information from the prompt\n",
    "student_info = student_processor.parse_student_info(student_prompt)\n",
    "\n",
    "# Create a student instance in the ontology\n",
    "student_instance = student_processor.create_student_instance(student_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance found by IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Farida_Test\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the instance by IRI pattern (assuming ontology uses \"Farida_Test\" directly in the IRI)\n",
    "farida_instance = student_processor.ontology.search_one(iri=\"*Farida_Test\")\n",
    "if farida_instance:\n",
    "    print(f\"Instance found by IRI: {farida_instance.iri}\")\n",
    "else:\n",
    "    print(\"Instance 'Farida_Test' not found by IRI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label assigned to Farida_Test: ['Farida_Test']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the instance by its IRI or existing reference\n",
    "farida_instance = onto.search_one(iri=\"*Farida_Test\")  # Adjust the pattern if needed\n",
    "\n",
    "if farida_instance:\n",
    "    # Assign the label\n",
    "    farida_instance.label = [\"Farida_Test\"]\n",
    "    print(f\"Label assigned to Farida_Test: {farida_instance.label}\")\n",
    "else:\n",
    "    print(\"Instance 'Farida_Test' could not be found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All instances in the ontology with labels:\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Advanced_Computer_Lab2, Label: Advanced Computer Lab2\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Advanced_Computer_Lab3, Label: Advanced Computer Lab3\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Theory_of_Computation, Label: Theory of Computation\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Introduction_to_Computer_Programming, Label: Introduction to Computer Programming\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Analysis_and_Design_of_Algorithms, Label: Analysis and Design of Algorithms\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Artificial_Intelligence, Label: Artificial Intelligence\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Data_Structures_and_Algorithms, Label: Data Structures and Algorithms\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Introduction_to_Computer_Science, Label: Introduction to Computer Science\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Bachelor_Thesis, Label: Bachelor Thesis\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Chem, Label: Chem\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#ChemLab, Label: ChemLab\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Compiler, Label: Compiler\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Computer_Graphics, Label: Computer Graphics\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Computer_Organization_and_System_Programming, Label: Computer Organization and System Programming\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Digital_Logic_Design, Label: Digital Logic Design\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Computer_Programming_Lab, Label: Computer Programming Lab\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Computer_System_Architecture, Label: Computer System Architecture\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Computer_Vision, Label: Computer Vision\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Concepts_of_Programming_Languages, Label: Concepts of Programming Languages\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Data_Base_I, Label: Data Base I\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Data_Bases_II, Label: Data Bases II\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Digital_System_Design, Label: Digital System Design\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Electric_Circuits_I, Label: Electric Circuits I\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Electric_Circuits_II, Label: Electric Circuits II\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Embedded_System_Architecture, Label: Embedded System Architecture\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Introduction_to_Communication_Networks, Label: Introduction to Communication Networks\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Introduction_to_Management, Label: Introduction to Management\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Introduction_to_Media_Engineering, Label: Introduction to Media Engineering\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Mathematics_I, Label: Mathematics I\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Maths, Label: Maths\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Mathematics_III, Label: Mathematics III\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Mathematics_IV_Probability_and_Statistics, Label: Mathematics IV Probability and Statistics\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Microprocessors, Label: Microprocessors\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Network_and_Media_Lab, Label: Network and Media Lab\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Operating_Systems, Label: Operating Systems\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Physics, Label: Physics\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Physics_II, Label: Physics II\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Production_Technology, Label: Production Technology\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Project_Management, Label: Project Management\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Seminar, Label: Seminar\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Signal_and_System_Theory, Label: Signal and System Theory\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Software_Engineering, Label: Software Engineering\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#'Advanced_Computer_Lab', Label: Advanced Computer Lab\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#'Computer_and_Network_Security', Label: Computer and Network Security\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Engineering_Drawing_&_Design, Label: Engineering Drawing & Design\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Mathematics_V_(Discrete_Math), Label: Mathematics V (Discrete Math)\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Physics_III_(p), Label: Physics III (p)\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Physics_III_(t), Label: Physics III (t)\n",
      "Instance IRI: http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#Farida_Test, Label: Farida_Test\n"
     ]
    }
   ],
   "source": [
    "# Print all individuals and their labels to confirm presence\n",
    "print(\"All instances in the ontology with labels:\")\n",
    "for instance in student_processor.ontology.individuals():\n",
    "    label = instance.label.first() if instance.label else \"No label\"\n",
    "    print(f\"Instance IRI: {instance.iri}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPA for Farida_Test: [2.78]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the 'Farida_Test' instance\n",
    "farida_instance = student_processor.find_instance_by_label(\"Farida_Test\")\n",
    "\n",
    "if farida_instance is not None:\n",
    "    # Check if GPA is assigned and print it\n",
    "    if hasattr(farida_instance, \"GPA\"):\n",
    "        print(f\"GPA for Farida_Test: {farida_instance.GPA}\")\n",
    "    else:\n",
    "        print(\"GPA property is not assigned to Farida_Test.\")\n",
    "else:\n",
    "    print(\"Instance 'Farida_Test' could not be found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses related to Farida_Test through the 'failed' property:\n",
      "- Analysis and Design of Algorithms\n",
      "- Computer Graphics\n",
      "- Analysis and Design of Algorithms\n",
      "- Computer Graphics\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the 'Farida_Test' instance\n",
    "farida_instance = onto.search_one(iri=\"*Farida_Test\")  # Adjust pattern if necessary\n",
    "\n",
    "if farida_instance:\n",
    "    # Check if the instance has a 'failed' property and print related objects\n",
    "    if hasattr(farida_instance, \"failed\"):\n",
    "        failed_courses = farida_instance.failed\n",
    "        print(\"Courses related to Farida_Test through the 'failed' property:\")\n",
    "        for course in failed_courses:\n",
    "            # Print the label if it exists, otherwise print the IRI\n",
    "            course_label = course.label.first() if course.label else course.iri\n",
    "            print(f\"- {course_label}\")\n",
    "    else:\n",
    "        print(\"The 'failed' property is not assigned to Farida_Test.\")\n",
    "else:\n",
    "    print(\"Instance 'Farida_Test' could not be found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses related to Farida_Test through the 'didNotTakeYet' (unattended) property:\n",
      "- Advanced Computer Lab3\n",
      "- Computer Vision\n",
      "- Advanced Computer Lab3\n",
      "- Computer Vision\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the 'Farida_Test' instance\n",
    "farida_instance = onto.search_one(iri=\"*Farida_Test\")  # Adjust pattern if necessary\n",
    "\n",
    "if farida_instance:\n",
    "    # Check if the instance has a 'didNotTakeYet' property and print related objects\n",
    "    if hasattr(farida_instance, \"didNotTakeYet\"):\n",
    "        unattended_courses = farida_instance.didNotTakeYet\n",
    "        print(\"Courses related to Farida_Test through the 'didNotTakeYet' (unattended) property:\")\n",
    "        for course in unattended_courses:\n",
    "            # Print the label if it exists, otherwise print the IRI\n",
    "            course_label = course.label.first() if course.label else course.iri\n",
    "            print(f\"- {course_label}\")\n",
    "    else:\n",
    "        print(\"The 'didNotTakeYet' (unattended courses) property is not assigned to Farida_Test.\")\n",
    "else:\n",
    "    print(\"Instance 'Farida_Test' could not be found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Case we want to remove an instance from the ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student instance 'Farida_Test' has been removed from the ontology.\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import destroy_entity\n",
    "\n",
    "def remove_student_instance(ontology, student_name):\n",
    "    \"\"\"\n",
    "    Removes a student instance from the ontology by name.\n",
    "    \"\"\"\n",
    "    # Search for the student instance by its name\n",
    "    student_instance = ontology.search_one(iri=f\"*{student_name}\")\n",
    "\n",
    "    if student_instance is None:\n",
    "        print(f\"Student instance '{student_name}' not found in the ontology.\")\n",
    "        return\n",
    "\n",
    "    # Remove the student instance\n",
    "    destroy_entity(student_instance)\n",
    "    print(f\"Student instance '{student_name}' has been removed from the ontology.\")\n",
    "\n",
    "# Usage example\n",
    "remove_student_instance(onto, \"Farida_Test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save updated Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated ontology\n",
    "onto.save(file=\"/Users/faridahelmy/Downloads/OntologyNew.rdf\", format=\"rdfxml\")  # Save as RDF/XML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.me.com', port=443): Max retries exceeded with url: /query?question=What+is+the+meaning+of+life%3F (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x1178c49d0>: Failed to resolve 'api.me.com' ([Errno 8] nodename nor servname provided, or not known)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/urllib3/connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    200\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[1;32m    201\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m    202\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[1;32m    203\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    205\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/urllib3/util/connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39mraise\u001b[39;00m LocationParseError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mhost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[1;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    961\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 962\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[1;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/urllib3/connectionpool.py:490\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    489\u001b[0m         new_e \u001b[39m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mscheme)\n\u001b[0;32m--> 490\u001b[0m     \u001b[39mraise\u001b[39;00m new_e\n\u001b[1;32m    492\u001b[0m \u001b[39m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[39m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    467\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[0;32m-> 1095\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1097\u001b[0m \u001b[39m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/urllib3/connection.py:693\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m sock: socket\u001b[39m.\u001b[39msocket \u001b[39m|\u001b[39m ssl\u001b[39m.\u001b[39mSSLSocket\n\u001b[0;32m--> 693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    694\u001b[0m server_hostname: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/urllib3/connection.py:206\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mraise\u001b[39;00m NameResolutionError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x1178c49d0>: Failed to resolve 'api.me.com' ([Errno 8] nodename nor servname provided, or not known)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    668\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    669\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    670\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    671\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    672\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    673\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    674\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    675\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    676\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    677\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    678\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    844\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    845\u001b[0m )\n\u001b[1;32m    846\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[39m=\u001b[39m error \u001b[39mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[39mfrom\u001b[39;00m \u001b[39mreason\u001b[39;00m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.me.com', port=443): Max retries exceeded with url: /query?question=What+is+the+meaning+of+life%3F (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x1178c49d0>: Failed to resolve 'api.me.com' ([Errno 8] nodename nor servname provided, or not known)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n\u001b[1;32m      9\u001b[0m \u001b[39m# Example usage:\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m answer \u001b[39m=\u001b[39m get_response(\u001b[39m\"\u001b[39;49m\u001b[39mWhat is the meaning of life?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(answer)\n",
      "Cell \u001b[0;32mIn[53], line 6\u001b[0m, in \u001b[0;36mget_response\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m      4\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://api.me.com/query\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m: question}\n\u001b[0;32m----> 6\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url, params\u001b[39m=\u001b[39;49mparams)\n\u001b[1;32m      7\u001b[0m \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/Desktop/Fuseki/venv/lib/python3.11/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    697\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    703\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.me.com', port=443): Max retries exceeded with url: /query?question=What+is+the+meaning+of+life%3F (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x1178c49d0>: Failed to resolve 'api.me.com' ([Errno 8] nodename nor servname provided, or not known)\"))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_response(question):\n",
    "    url = \"https://api.me.com/query\"\n",
    "    params = {\"question\": question}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "# Example usage:\n",
    "answer = get_response(\"What is the meaning of life?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = {\n",
    "    \"GPA\": 2.78,\n",
    "    \"failed_courses\": [\"Computer_Graphics\", \"Analysis_and_Design_of_Algorithms\", \"Data_Structures_and_Algorithms\"],\n",
    "    \"unattended_courses\": [\"Data_Bases_II\", \"Advanced_Computer_Lab3\", \"Theory_of_Computation\", \"Compiler\"],\n",
    "    \"allowed_credit_hours\": 34,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, URIRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ontology namespace\n",
    "ONTOLOGY_NS = Namespace(\"http://www.semanticweb.org/faridahelmy/ontologies/2024/10/untitled-ontology-11#\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Naf66379b0bc54e6ca860fd53f677bcbc (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize RDF Graph\n",
    "g = Graph()\n",
    "g.parse(\"/Users/faridahelmy/Downloads/OntologyNew.rdf\", format=\"xml\")  # Load your ontology file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remaining_courses_details(graph, courses):\n",
    "    \"\"\"Fetch details for failed and unattended courses, including semester labels.\"\"\"\n",
    "    course_uris = \", \".join([f\"<{ONTOLOGY_NS}{course}>\" for course in courses])\n",
    "    query = f\"\"\"\n",
    "    PREFIX : <{ONTOLOGY_NS}>\n",
    "    SELECT ?course ?prerequisite ?creditHours ?isOddCourse ?isEvenCourse\n",
    "    WHERE {{\n",
    "      ?course a :Course ;\n",
    "              :creditHours ?creditHours .\n",
    "      OPTIONAL {{ ?course :hasPrerequisite ?prerequisite . }}\n",
    "      OPTIONAL {{ ?course :oddSemester ?isOddCourse . }}\n",
    "      OPTIONAL {{ ?course :evenSemester ?isEvenCourse . }}\n",
    "      FILTER (?course IN ({course_uris}))\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return graph.query(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_passed_courses(graph, failed_courses, unattended_courses):\n",
    "    \"\"\"\n",
    "    Infer passed courses dynamically by excluding failed and unattended courses.\n",
    "    \"\"\"\n",
    "    # Convert lists to SPARQL-compatible format\n",
    "    failed_courses_uris = \", \".join([f\"<{ONTOLOGY_NS}{course}>\" for course in failed_courses])\n",
    "    unattended_courses_uris = \", \".join([f\"<{ONTOLOGY_NS}{course}>\" for course in unattended_courses])\n",
    "\n",
    "    # SPARQL query to fetch all courses not in failed or unattended courses\n",
    "    query = f\"\"\"\n",
    "    PREFIX : <{ONTOLOGY_NS}>\n",
    "    SELECT ?course\n",
    "    WHERE {{\n",
    "      ?course a :Course .\n",
    "      FILTER (?course NOT IN ({failed_courses_uris}, {unattended_courses_uris}))\n",
    "    }}\n",
    "    \"\"\"\n",
    "    results = graph.query(query)\n",
    "\n",
    "    # Collect all passed courses\n",
    "    passed_courses = [str(row[0]).split(\"#\")[-1] for row in results]\n",
    "\n",
    "    return passed_courses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_course_prerequisites(graph, course):\n",
    "    \"\"\"Fetch prerequisites for a specific course.\"\"\"\n",
    "    query = f\"\"\"\n",
    "    PREFIX : <{ONTOLOGY_NS}>\n",
    "    SELECT ?prerequisite\n",
    "    WHERE {{\n",
    "      <{ONTOLOGY_NS}{course}> :hasPrerequisite ?prerequisite .\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return [str(row[0]).split(\"#\")[-1] for row in graph.query(query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_courses_by_semester(course_details):\n",
    "    \"\"\"Split courses into odd and even semesters.\"\"\"\n",
    "    odd_semester = [course for course, details in course_details.items() if details[\"oddSemester\"]]\n",
    "    even_semester = [course for course, details in course_details.items() if not details[\"oddSemester\"]]\n",
    "    return odd_semester, even_semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prioritize_courses(failed_courses, unattended_courses, odd_courses, even_courses):\n",
    "    \"\"\"Prioritize failed courses over unattended courses.\"\"\"\n",
    "    prioritized_odd = [c for c in failed_courses if c in odd_courses] + [c for c in unattended_courses if c in odd_courses]\n",
    "    prioritized_even = [c for c in failed_courses if c in even_courses] + [c for c in unattended_courses if c in even_courses]\n",
    "    return prioritized_odd, prioritized_even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule_courses(odd_courses, even_courses, credit_limit, course_details):\n",
    "    \"\"\"Schedule courses without exceeding the credit hour limit.\"\"\"\n",
    "    schedule = {\"Odd Semester\": [], \"Even Semester\": []}\n",
    "    current_credits = 0\n",
    "\n",
    "    for semester, courses in [(\"Odd Semester\", odd_courses), (\"Even Semester\", even_courses)]:\n",
    "        for course in courses:\n",
    "            if current_credits + course_details[course][\"creditHours\"] <= credit_limit:\n",
    "                schedule[semester].append(course)\n",
    "                current_credits += course_details[course][\"creditHours\"]\n",
    "    return schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graduation_plan(graph, student_data):\n",
    "    # Step 1: Fetch course details\n",
    "    print(\"Fetching course details...\")\n",
    "    all_courses = student_data[\"failed_courses\"] + student_data[\"unattended_courses\"]\n",
    "    print(\"All Courses:\", all_courses)\n",
    "    results = get_remaining_courses_details(graph, all_courses)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Step 2: Process course details\n",
    "    print(\"Processing course details...\")\n",
    "    course_details = {}\n",
    "    for row in results:\n",
    "        course = str(row[0]).split(\"#\")[-1]\n",
    "        prerequisite = str(row[1]).split(\"#\")[-1] if row[1] else None\n",
    "        credit_hours = float(row[2].toPython())  # Handles decimal credit hours\n",
    "        odd_semester = row[3].toPython() if row[3] else False  # Default to False if missing\n",
    "        even_semester = row[4].toPython() if row[4] else False  # Default to False if missing\n",
    "\n",
    "        if course not in course_details:\n",
    "            course_details[course] = {\n",
    "                \"prerequisites\": [],\n",
    "                \"creditHours\": credit_hours,\n",
    "                \"oddSemester\": odd_semester,\n",
    "                \"evenSemester\": even_semester,\n",
    "            }\n",
    "        if prerequisite:\n",
    "            course_details[course][\"prerequisites\"].append(prerequisite)\n",
    "\n",
    "    # Log course details\n",
    "    print(\"Course Details:\", course_details)\n",
    "\n",
    "    # Step 3: Infer passed courses dynamically\n",
    "    print(\"Inferring passed courses...\")\n",
    "    student_data[\"passed_courses\"] = get_passed_courses(\n",
    "        graph=graph,\n",
    "        failed_courses=student_data[\"failed_courses\"],\n",
    "        unattended_courses=student_data[\"unattended_courses\"],\n",
    "    )\n",
    "    print(\"Passed Courses:\", student_data[\"passed_courses\"])\n",
    "\n",
    "    # Step 4: Filter courses based on prerequisites\n",
    "    print(\"Filtering eligible courses...\")\n",
    "    eligible_courses = {\n",
    "    course: details\n",
    "    for course, details in course_details.items()\n",
    "    if (not details.get(\"prerequisites\", []) or  # Include courses with no prerequisites or an empty list\n",
    "        all(prereq in student_data[\"passed_courses\"] for prereq in details[\"prerequisites\"]))\n",
    "}\n",
    "    print(\"Eligible Courses:\", eligible_courses)\n",
    "\n",
    "    # Step 5: Split courses into odd/even semesters\n",
    "    print(\"Splitting courses by semester...\")\n",
    "    odd_courses, even_courses = split_courses_by_semester(eligible_courses)\n",
    "    print(\"Odd Semester Courses:\", odd_courses)\n",
    "    print(\"Even Semester Courses:\", even_courses)\n",
    "\n",
    "    # Step 6: Prioritize courses\n",
    "    print(\"Prioritizing courses...\")\n",
    "    prioritized_odd, prioritized_even = prioritize_courses(\n",
    "        student_data[\"failed_courses\"],\n",
    "        student_data[\"unattended_courses\"],\n",
    "        odd_courses,\n",
    "        even_courses,\n",
    "    )\n",
    "    print(\"Prioritized Odd Semester:\", prioritized_odd)\n",
    "    print(\"Prioritized Even Semester:\", prioritized_even)\n",
    "\n",
    "    # Step 7: Schedule courses\n",
    "    print(\"Scheduling courses...\")\n",
    "    schedule = schedule_courses(\n",
    "        prioritized_odd, prioritized_even, student_data[\"allowed_credit_hours\"], eligible_courses\n",
    "    )\n",
    "    print(\"Final Schedule:\", schedule)\n",
    "\n",
    "    return schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching course details...\n",
      "All Courses: ['Computer_Graphics', 'Analysis_and_Design_of_Algorithms', 'Data_Structures_and_Algorithms', 'Data_Bases_II', 'Advanced_Computer_Lab3', 'Theory_of_Computation', 'Compiler']\n",
      "Processing course details...\n",
      "Course Details: {'Advanced_Computer_Lab3': {'prerequisites': ['Theory_of_Computation'], 'creditHours': 4.0, 'oddSemester': False, 'evenSemester': True}, 'Analysis_and_Design_of_Algorithms': {'prerequisites': [], 'creditHours': 4.0, 'oddSemester': True, 'evenSemester': False}, 'Compiler': {'prerequisites': ['Theory_of_Computation'], 'creditHours': 4.0, 'oddSemester': False, 'evenSemester': True}, 'Computer_Graphics': {'prerequisites': ['Data_Structures_and_Algorithms', 'Introduction_to_Computer_Programming'], 'creditHours': 6.0, 'oddSemester': True, 'evenSemester': False}, 'Data_Bases_II': {'prerequisites': ['Data_Base_I'], 'creditHours': 4.0, 'oddSemester': False, 'evenSemester': True}, 'Data_Structures_and_Algorithms': {'prerequisites': ['Introduction_to_Computer_Programming', 'Introduction_to_Computer_Science'], 'creditHours': 6.0, 'oddSemester': True, 'evenSemester': False}, 'Theory_of_Computation': {'prerequisites': ['Introduction_to_Computer_Programming'], 'creditHours': 6.0, 'oddSemester': True, 'evenSemester': False}}\n",
      "Inferring passed courses...\n",
      "Passed Courses: ['Advanced_Computer_Lab2', 'Artificial_Intelligence', 'Bachelor_Thesis', 'Chem', 'ChemLab', 'Computer_Organization_and_System_Programming', 'Computer_Programming_Lab', 'Computer_System_Architecture', 'Computer_Vision', 'Concepts_of_Programming_Languages', 'Data_Base_I', 'Digital_Logic_Design', 'Digital_System_Design', 'Electric_Circuits_I', 'Electric_Circuits_II', 'Embedded_System_Architecture', 'Introduction_to_Communication_Networks', 'Introduction_to_Computer_Programming', 'Introduction_to_Computer_Science', 'Introduction_to_Management', 'Introduction_to_Media_Engineering', 'Mathematics_I', 'Mathematics_III', 'Mathematics_IV_Probability_and_Statistics', 'Maths', 'Microprocessors', 'Network_and_Media_Lab', 'Operating_Systems', 'Physics', 'Physics_II', 'Production_Technology', 'Project_Management', 'Seminar', 'Signal_and_System_Theory', 'Software_Engineering', \"'Advanced_Computer_Lab'\", \"'Computer_and_Network_Security'\", 'Engineering_Drawing_&_Design', 'Mathematics_V_(Discrete_Math)', 'Physics_III_(p)', 'Physics_III_(t)']\n",
      "Filtering eligible courses...\n",
      "Eligible Courses: {'Analysis_and_Design_of_Algorithms': {'prerequisites': [], 'creditHours': 4.0, 'oddSemester': True, 'evenSemester': False}, 'Data_Bases_II': {'prerequisites': ['Data_Base_I'], 'creditHours': 4.0, 'oddSemester': False, 'evenSemester': True}, 'Data_Structures_and_Algorithms': {'prerequisites': ['Introduction_to_Computer_Programming', 'Introduction_to_Computer_Science'], 'creditHours': 6.0, 'oddSemester': True, 'evenSemester': False}, 'Theory_of_Computation': {'prerequisites': ['Introduction_to_Computer_Programming'], 'creditHours': 6.0, 'oddSemester': True, 'evenSemester': False}}\n",
      "Splitting courses by semester...\n",
      "Odd Semester Courses: ['Analysis_and_Design_of_Algorithms', 'Data_Structures_and_Algorithms', 'Theory_of_Computation']\n",
      "Even Semester Courses: ['Data_Bases_II']\n",
      "Prioritizing courses...\n",
      "Prioritized Odd Semester: ['Analysis_and_Design_of_Algorithms', 'Data_Structures_and_Algorithms', 'Theory_of_Computation']\n",
      "Prioritized Even Semester: ['Data_Bases_II']\n",
      "Scheduling courses...\n",
      "Final Schedule: {'Odd Semester': ['Analysis_and_Design_of_Algorithms', 'Data_Structures_and_Algorithms', 'Theory_of_Computation'], 'Even Semester': ['Data_Bases_II']}\n",
      "Graduation Plan: {'Odd Semester': ['Analysis_and_Design_of_Algorithms', 'Data_Structures_and_Algorithms', 'Theory_of_Computation'], 'Even Semester': ['Data_Bases_II']}\n"
     ]
    }
   ],
   "source": [
    "# Generate Graduation Plan\n",
    "graduation_plan = generate_graduation_plan(g, student_data)\n",
    "\n",
    "# Output Plan\n",
    "print(\"Graduation Plan:\", graduation_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a34731dd9b7b03372d6329e1e8cbb772da23dbf7cdfdcb52eae5554a8cf40481"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
